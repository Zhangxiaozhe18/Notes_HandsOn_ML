{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "First, let's make sure this notebook works well in both python 2 and 3, import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"deep\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanishing/Exploding Gradients Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure sigmoid_saturation_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [1, 1], 'k--')\n",
    "plt.plot([0, 0], [-0.2, 1.2], 'k-')\n",
    "plt.plot([-5, 5], [-3/4, 7/4], 'g--')\n",
    "plt.plot(z, logit(z), \"b-\", linewidth=2)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Saturating', xytext=(3.5, 0.7), xy=(5, 1), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('Saturating', xytext=(-3.5, 0.3), xy=(-5, 0), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('Linear', xytext=(2, 0.2), xy=(0, 0.5), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.grid(True)\n",
    "plt.title(\"Sigmoid activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.2, 1.2])\n",
    "\n",
    "save_fig(\"sigmoid_saturation_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xavier and He Initialization\n",
    "Note: the book uses tensorflow.contrib.layers.fully_connected() rather than tf.layers.dense() (which did not exist when this chapter was written). It is now preferable to use tf.layers.dense(), because anything in the contrib module may change or be deleted without notice. The dense() function is almost identical to the fully_connected() function. The main differences relevant to this chapter are:\n",
    "\n",
    "several parameters are renamed: scope becomes name, activation_fn becomes activation (and similarly the _fn suffix is removed from other parameters such as normalizer_fn), weights_initializer becomes kernel_initializer, etc.\n",
    "the default activation is now None rather than tf.nn.relu.\n",
    "it does not support tensorflow.contrib.framework.arg_scope() (introduced later in chapter 11).\n",
    "it does not support regularizer params (introduced later in chapter 11)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-da109dac52d3>:3: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    }
   ],
   "source": [
    "he_init = tf.variance_scaling_initializer()\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,\n",
    "                          kernel_initializer=he_init, name=\"hidden1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonsaturating Activation Functions\n",
    "Leaky ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(z, alpha=0.01):\n",
    "    return np.maximum(alpha*z, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure leaky_relu_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, leaky_relu(z, 0.05), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([0, 0], [-0.5, 4.2], 'k-')\n",
    "plt.grid(True)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Leak', xytext=(-3.5, 0.5), xy=(-5, -0.2), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.title(\"Leaky ReLU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.5, 4.2])\n",
    "\n",
    "save_fig(\"leaky_relu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing Leaky ReLU in TensorFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "def leaky_relu(z, name=None):\n",
    "    return tf.maximum(0.01 * z, z, name=name)\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=leaky_relu, name=\"hidden1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a neural network on MNIST using the Leaky ReLU. First let's create the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=leaky_relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=leaky_relu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data:\n",
    "\n",
    "Warning: tf.examples.tutorials.mnist is deprecated. We will use tf.keras.datasets.mnist instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
    "y_valid, y_train = y_train[:5000], y_train[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Batch accuracy: 0.86 Validation accuracy: 0.9046\n",
      "5 Batch accuracy: 0.94 Validation accuracy: 0.9498\n",
      "10 Batch accuracy: 0.92 Validation accuracy: 0.9656\n",
      "15 Batch accuracy: 0.94 Validation accuracy: 0.9706\n",
      "20 Batch accuracy: 1.0 Validation accuracy: 0.976\n",
      "25 Batch accuracy: 1.0 Validation accuracy: 0.9774\n",
      "30 Batch accuracy: 0.98 Validation accuracy: 0.978\n",
      "35 Batch accuracy: 1.0 Validation accuracy: 0.9786\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 5 == 0:\n",
    "            acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "            acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "            print(epoch, \"Batch accuracy:\", acc_batch, \"Validation accuracy:\", acc_valid)\n",
    "\n",
    "    save_path = saver.save(sess, r\"./tf_logs/LeakyReLU/my_model_final.ckpt\")\n",
    "    file_writer = tf.summary.FileWriter(r\"./tf_logs/LeakyReLU\", tf.get_default_graph())\n",
    "    file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elu(z, alpha=1):\n",
    "    return np.where(z < 0, alpha * (np.exp(z) - 1), z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure elu_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deZgU1dn38e8Ng+wgiI4LIkYFNURImOSJGnViiALBYNTgHtEYCIRXiZqovOjja3g0GkwwKigGHyLggrgEkcUltogSFXEIEAFBZFX2BoZtmJnz/nF6cOhZm6mZqp7+fa6rrump013n7jM1fXedOnXKnHOIiIhETYOwAxARESmPEpSIiESSEpSIiESSEpSIiESSEpSIiESSEpSIiESSEpSIiESSEpSIiESSEpSkHTMbb2bT6lE9DczsCTPbYmbOzHJru85KYqmT95yoq42ZbTCzk+qivlSZ2QtmdmvYcWQy00wS9ZuZjQeuK6foA+fc9xPl7ZxzfSp4fQxY5JwbkrS+P/Coc65FoAFXr+7W+H03nk71VFJ/H+AlIBf4HNjqnCuozToT9cZIet919Z4Tdf0Jv+9dX9t1lVP3ucBtQHfgWOB659z4pOd8C3gHONE5t72uYxTICjsAqRNvAtcmrav1D8DaUlcfFnX4oXQy8KVz7v06qq9CdfWezawZcCNwUV3UV44WwCLg6cRShnNuoZl9DlwDPFaHsUmCuvgywz7n3FdJy9bartTMeprZu2a2zcy2mtksMzutVLmZ2a1m9pmZ7TOztWZ2f6JsPHAe8JtEt5czs44lZWY2zcwGJLqIGibV+4yZTa1OHNWpp9R2GpvZqESde83sX2b2g1LlMTMbbWb3mdlmM9toZiPNrML/s0T9fwE6JOr+otS2Hk1+bkk81anrUNo31fd8qO8b6A044L1y2qS7mb1lZnvMbLmZnWtm/cyszHMPlXNuunNumHNuClBcyVOnAlcGVa+kRglKalNzYBTwPXz31XbgVTM7LFF+H3AXcD/wTeDnwJpE2c3AXOB/gWMSS0lZiReA1sCPS1aYWQugLzCxmnFUp54SDwKXAzcA3wYWAjPN7JhSz7kaKATOAoYAQxOvqcjNwL3A2kTd363kucmqqqum7QvVe8/ViSXZOcDHLukcg5l9F3gXeBs4A/gX8P+A/5t4LyQ9f5iZ5VexnFNJHFX5EPiemTWtwTbkEKmLLzP0NLP8pHWPOedur81KnXMvlv7dzK4HduD/4fOA3wJDnXNPJZ6yHP+hiXNuu5kVALudc19VsP1tZjYd/+E4M7H6YvwH5dRSz6swDufcnKrqSbymOTAIuNE591pi3a+B84HfAMMTT/2Pc+7uxONlZvYr4EfAsxW8h+1mthMoqqz+ClRYVyJRp9y+ZnYo7znl9w2cAKwvZ/1DwKvOuRGJ+p4BXgVmO+f+Wc7zHwcmV1BHiXVVlFdmPdAIf55qRQ22I4dACSozzAYGJK2ri5PgJwF/AP4LOBJ/xN4A6IA/B9YYeKuG1UwE/m5mzZxzu/HJ6kXn3N5qxlFdJ+E/qA50MznnisxsLnB6qef9O+l164GjUqgnFZXVdTo1b9/qvueqYilPU2BD6RVmdjT+yOqHpVYX4P9WZY6eEvFsBWqzu3pP4qeOoEKgBJUZdjvnlh/ia3fgu9GSHY7vKqvMNHzX1UD8t9hC4D/AYZW9KEWvJbbb18zeAnoAF9ZxHKW7qfaXU3YoXenFgCWta5T0e1B1HYrk4b+pxrIZaJO0ruT85LxS6zoDS51zc8rbiJkNA4ZVHiq9nHPvVvGcirRN/Nx0iK+XGlCCkqosBXqbmSWdL/hOoqxcZnYEcCow2Dn3dmLdd/h6n/sU2IfvBvqsgs0UAA0rKAPAObfPzF7AHzm1A74CYinEUa168N07BcDZiceYH5xxJvBMFa89FJvw54VK6wp8Uc3XB9G+tfmePwH6J607HJ/YihJ1tcSfe6qs67O2u/i6AOuccxuqfKYETgkqMzROdJ+UVuScK/lW2MrMuiWVx51zXwBj8Ce9HzGzJ4G9+BFYVwI/raTObfhvyb8yszXAccCf8EcvOOd2mtnDwP1mtg/fDXkE0N05NyaxjS/w56s6Avn464PKG3E1Ed+VdSLwbNJzKo2juvU453aZ2RjgATPbDKzEn+PJBkZX0g6H6p/AKDP7Kf6LwEDgeKqZoA61fZO2UZvveVZiu0c457Yk1uXhjxrvNLNJ+L/Tl8DJZnaKc65Moj3ULr7EObqTE782wI+i7Ib/268u9dRzErFKCDSKLzP0wP+jl14+KVV+TuL30stIAOfc58C5wCnA6/hRTVcAP3fOzaiowsQH/OX4kViL8NeR3IX/Vl/iTuCBxPpPgReB9qXKR+K/wf8Hf0RR0Tmjd/Hfkk/n4NF71Y2juvXcDjyPH/mWl9hmT+fclxU8vyaeKrW8B+wEXk5xG0G0b628Z+fcQr7el0rWrcQfMQ0CFuDfcw/83y3oa8Ry+Hpfb4ofKfgJfkQlAGbWBPgZ8GTAdUs1aSYJEQmFmfUEHgZOd84VhR1PMjP7DdDXOXdB2LFkKh1BiUgonHMz8Ue07at6bkj2A/8n7CAymY6gREQkknQEJSIikaQEJSIikRT6MPN27dq5jh07hh1GGbt27aJ58+Zhh5F21G6pWbp0KUVFRZx+evLEDFKZdNrPnIPly2HHDjjsMDj1VGiUfMl1HYhym3388cebnXNHJq8PPUF17NiRefPmVf3EOhaLxcjNzQ07jLSjdktNbm4u8Xg8kv8DUZYu+1lxMVx1FcyfD0cdBXPmwCmnhBNLlNvMzFaVt15dfCIitcA5uPlmeP55aNkSZswILzmlKyUoEZFaMGIEPPqo79b7xz/gO98JO6L0owQlIhKwxx+Hu++GBg3g2Wfhhz+s+jVSVqAJyswmmtmXZrbDzJaZ2Y1Bbl9EJOqmTIHBg/3jMWPgkkvCjSedBX0EdT/Q0TnXCj+R6Agz6x5wHSIikfTWW3D11f7804gRMCD5LmySkkATlHNusXOuZBJOl1hOCrIOEZEo+vhjuPhiKCiAm26CYVXdpUqqFPgwczMbjb/PS1P87MDTy3nOABJ3eM3OziYWiwUdRo3l5+dHMq6oU7ulJh6PU1RUpDZLUdT2szVrmnLTTd8mP/8wzj9/A337fso774Qd1cGi1mbVUStz8ZW6qVku8IBzLvlumwfk5OS4KF4DEuVrBqJM7Zaakuug8vLywg4lrURpP1u/Hs46C1atggsvhKlT/ci9qIlSmyUzs4+dcznJ62tlFJ9zrihxi+b2+Hu7iIjUO9u2+aS0ahX813/Biy9GMzmlq9oeZp6FzkGJSD20ezdcdBEsWgSnnQavvQYRnUkobQWWoMzsKDO7wsxamFlDM7sQf1vwt4KqQ0QkCvbvh3794L33oH17mDULjjgi7KjqnyAHSTh8d97j+MS3ChjqnJsaYB0iIqEqLoYbb/RHTG3bwuuvw/HHhx1V/RRYgnLObQLOC2p7IiJRdPvt8PTT0KwZTJ/uu/ekdmiqIxGRavrTn2DkSMjKgpde8gMjpPYoQYmIVMP//i/8/vf+8dNP+9F7UruUoEREqjB1KvzqV/7xww/DlVeGG0+mUIISEanEu+/C5ZdDUREMH+6nMZK6oQQlIlKBf//bX+u0d6+f+PXee8OOKLMoQYmIlGPlSn+eaft2f8uM0aPBLOyoMosSlIhIkg0b4IIL4Kuv/M0GJ02Chg3DjirzKEGJiJSyYwf06gXLl8O3vw2vvAJNmoQdVWZSghIRSdi719/T6ZNP4OSTYcYMaNUq7KgylxKUiAh+lN7VV8Pbb8PRR/spjLKzw44qsylBiUjGcw4GD/azQ7Ru7Sd/PfHEsKMSJSgRyXh33w1jx/pzTa++CmecEXZEAkpQIpLh/vpXGDHCj9KbPBnOOSfsiKSEEpSIZKxnnoGbb/aP//Y3f1GuRIcSlIhkpJkz4brr/OMHH4T+/UMNR8qhBCUiGeeDD+DSS6GwEG67DX73u7AjkvIoQYlIRvn0U+jdG3bv9kdQDzwQdkRSESUoEckYa9b4KYy2boU+feDJJ6GBPgUjS38aEckIW7b45LR2LZx9Njz/PDRqFHZUUhklKBGp9/Lz4Sc/gSVLoEsXf61Ts2ZhRyVVUYISkXqtoAAuu8wPjDjhBD9LRJs2YUcl1aEEJSL1VnGxHz4+axYceaSfX+/YY8OOSqpLCUpE6iXnYOhQePZZaNHCz0zeqVPYUUkqlKBEpF667z545BE47DD4xz+ge/ewI5JUKUGJSL0zdiwMH+5v0T5pEpx/ftgRyaFQghKReuXFF2HQIP949Gg/QELSkxKUiNQbb78NV13lB0fcey/8+tdhRyQ1oQQlIvXC/PnQt68fVj5kiO/ik/SmBCUiae+zz6BnT9i5E664Ah5+2J9/kvSmBCUiaW39ej+F0aZN/uff/6759eoL/RlFJG3F4/7I6Ysv4Hvf8wMkDjss7KgkKEpQIpKW9uzxd8BduBA6d4bXXvMX5Er9EViCMrPGZjbOzFaZ2U4zyzOzXkFtX0SkRFGRcfnlMGcOHHecn8KoXbuwo5KgBXkElQWsAc4DWgPDgclm1jHAOkQkwzkHI0d24tVX/aSvr78OHTqEHZXUhqygNuSc2wXcU2rVNDNbCXQHvgiqHhHJbHfcATNnHkOzZr5b7/TTw45IakutnYMys2ygE7C4tuoQkcwyciQ8+CA0bFjMlClw5plhRyS1KbAjqNLMrBEwCfi7c25JOeUDgAEA2dnZxGKx2gijRvLz8yMZV9Sp3VITj8cpKipSm1XDzJnZPPDAaQAMHbqApk23o2arvnT83zTnXLAbNGsAPAO0Avo65/ZX9vycnBw3b968QGMIQiwWIzc3N+ww0o7aLTW5ubnE43Hy8vLCDiXSpk2Diy+GoiIYNQq6dtV+lqoo/2+a2cfOuZzk9YF28ZmZAeOAbODSqpKTiEhV5syBn//cJ6dhw+Dmm8OOSOpK0F18Y4DTgB7OuT0Bb1tEMszChf5ap7174cYbYcSIsCOSuhTkdVAnAAOBbsBXZpafWK4Oqg4RyRxffAEXXuhni/jZz2DMGM2vl2mCHGa+CtDuIyI1tnGjn1fvyy/hvPPgmWcgq1aGdEmUaaojEYmUHTugVy8/Q3m3bv527U2ahB2VhEEJSkQiY98+3503fz6cdBLMnAmtW4cdlYRFCUpEIqGoCK65Bv75Tzj6aD+FUXZ22FFJmJSgRCR0zsFvfgNTpkCrVv7I6RvfCDsqCZsSlIiE7p574IknoHFjePVV6No17IgkCpSgRCRUjz4K997r74L7/PNw7rlhRyRRoQQlIqF57jm46Sb/+MknoW/fcOORaFGCEpFQvP46/OIX/vzTH/8IN9wQdkQSNUpQIlLnPvwQLrkE9u+HW26B3/8+7IgkipSgRKROLVkCvXvDrl1w7bXwpz9pCiMpnxKUiNSZtWv9FEZbtvgkNW6cHxwhUh7tGiJSJ7Zs8clpzRo46yx44QVo1CjsqCTKlKBEpNbt2gV9+sCnn8I3v+mvdWrWLOyoJOqUoESkVu3fD5ddBv/6F3ToALNmQdu2YUcl6UAJSkRqTXExXH+9n7qoXTs/tPy448KOStKFEpSI1Arn/BDySZOgRQuYMQM6dw47KkknSlAiUiv++Ed4+GE/EOLllyEnJ+yIJN0oQYlI4P72Nxg2zF/fNHEi9OgRdkSSjpSgRCRQL78MAwf6x489Bv36hRuPpC8lKBEJTCwGV17pB0fccw8MGhR2RJLOlKBEJBCffAI//am/bfvgwXD33WFHJOlOCUpEamz5cujZE3bu9F16f/2r5teTmlOCEpEa+fJLuPBC2LjRD4Z4+mlo2DDsqKQ+UIISkUMWj0OvXvD5534Y+Usv+du2iwRBCUpEDsmePf4OuAsWQKdOMH06tGwZdlRSnyhBiUjKCgv9aL3Zs+HYY/0URkceGXZUUt8oQYlISpzz1zn94x/Qpo1PTiecEHZUUh8pQYlISoYNg6eegqZNYdo0f/sMkdqgBCUi1fbnP/s59ho2hClT/I0HRWqLEpSIVMuECXDrrf7x+PH+lu0itUkJSkSq9Npr/r5OAH/5C1xzTbjxSGZQghKRSr3/Pvz851BUBHfeCUOHhh2RZAolKBGp0KJF8JOf+GuefvlL+J//CTsiySSBJigzG2Jm88xsn5mND3LbIlK3Vq3yUxjF43DxxfD445pfT+pWVsDbWw+MAC4Emga8bRGpI5s2wQUXwPr1cN558OyzkBX0p4VIFQLd5ZxzLwGYWQ7QPshti0jd2LnTj9Bbtgy6dvUX5DZpEnZUkolC+U5kZgOAAQDZ2dnEYrEwwqhUfn5+JOOKOrVbauLxOEVFRZFps4IC4847z2D+/DYce+we7r77Ez75pCDssMrQfpa6dGyzUBKUc24sMBYgJyfH5ebmhhFGpWKxGFGMK+rUbqk5/PDDicfjkWizoiI/v978+ZCdDbNnN+Wkk6J5Ja72s9SlY5tpFJ+I4BzcdBO88AK0agUzZ8JJJ4UdlWQ6JSgR4d57YfRofy+nqVOhW7ewIxIJuIvPzLIS22wINDSzJkChc64wyHpEJDijR8M990CDBvDcc37UnkgUBH0ENRzYA9wBXJN4PDzgOkQkIJMnw5Ah/vHYsf56J5GoCHqY+T3APUFuU0Rqx5tv+jn1nIP77/czRYhEic5BiWSgjz7yR0v798Nvfwu33x52RCJlKUGJZJilS/2FuLt2+SOokSM1hZFEkxKUSAZZt85PYbR5M/Tq5e+M20CfAhJR2jVFMsTWrX7y19Wr4cwz/TVPjRqFHZVIxZSgRDLA7t3Qpw8sXgynnw7TpkHz5mFHJVI5JSiRem7/fn/DwblzoUMHmDUL2rYNOyqRqilBidRjxcVwww0wfTq0awevvw7tdZ8BSRNKUCL1lHNw220wcaLvzps+HTp3DjsqkepTghKppx58EP7yFz8Q4uWX4bvfDTsikdQoQYnUQ+PGwR13+OubJk6EH/847IhEUqcEJVLPvPIKDBjgHz/6KPTrF248IodKCUqkHpk9G664wg+O+O//hsGDw45I5NApQYnUEwsWwEUXwb59MGiQT1Ai6UwJSqQe+PxzP0vEjh3+mqdHHtH8epL+lKBE0txXX/n59TZsgB/9CCZMgIYNw45KpOaUoETS2PbtftLXFSuge3c/nLxx47CjEgmGEpRImtq7F/r2hbw86NQJZsyAli3DjkokOEpQImmosBCuvBLeeQeOPdbPr3fkkWFHJRIsJSiRNOOcH6X3yitw+OE+OXXsGHZUIsFTghJJM8OHw9/+Bk2b+ttmdOkSdkQitUMJSiSNjBoF993nR+m98AKcfXbYEYnUHiUokTQxaRL89rf+8VNPwU9+Em48IrVNCUokDcyYAf37+8cPPQS/+EWo4YjUCSUokYibOxcuvdSP3Lv9drjllrAjEqkbSlAiEbZ4se/K27PH3xn3/vvDjkik7ihBiUTU6tV+fr1t2+CnP4UnntD8epJZlKBEImjzZj+/3rp1cM458NxzkJUVdlQidUsJSiRi8vOhd29YuhTOOAOmTvXXPIlkGiUokQgpKIBLLoGPPoITT4SZM/1sESKZSAlKJCKKi/3w8TfegKOOgtdfh2OOCTsqkfAoQYlEgHNw883w/PN+RvKZM+Hkk8OOSiRcSlAiETBiBDz6KBx2mD/n9O1vhx2RSPgCTVBm1tbMXjazXWa2ysyuCnL7IvXRli2NuftuaNAAnn0WcnPDjkgkGoIeuPoYUABkA92A18xsgXNuccD1iNQLmzbB2rV+iN7jj/sBEiLimXMumA2ZNQe2AV2cc8sS6yYA65xzd1T0upYtW7ru3bsHEkOQ4vE4h2v4VMrUbtW3dSssXJgHwIkndqNDh5ADSiPaz1IX5TZ75513PnbO5SSvD/IIqhNQWJKcEhYA5yU/0cwGAAMAGjVqRDweDzCMYBQVFUUyrqhTu1VPfn4Wn3/eHICsrGJatYqjZqs+7WepS8c2CzJBtQB2JK3bDrRMfqJzbiwwFiAnJ8fNmzcvwDCCEYvFyNXJgJSp3ao2bx6cf74fuXfMMbkcdVScvLy8sMNKK9rPUhflNrMK5vAKcpBEPtAqaV0rYGeAdYiktbw86NkTdu6EK66AU04JOyKR6AoyQS0Dssys9L9cV0ADJESADz+EH/4QtmyBPn3g6ac1+atIZQJLUM65XcBLwL1m1tzMzgb6AhOCqkMkXc2ZAz16QDwOF18MU6ZAo0ZhRyUSbUFfqDsYaApsBJ4FBmmIuWS6f/7T3zajpFtv8mRo3DjsqESiL9DroJxzW4GLg9ymSDp74QW49lrYtw+uuw7GjYOGDcOOSiQ9aKojkVrgHIwcCf36+eQ0eDA89ZSSk0gqlKBEAlZYCEOGwO9+539/4AE/z14D/beJpET36BQJ0PbtcPXV8NprfuLXp5+Gyy8POyqR9KQEJRKQRYv8XHqffQZt28Irr/jbtYvIoVGng0gAJk+G73/fJ6euXf0dcZWcRGpGCUqkBvbtg1tu8d14u3b57r3334dvfCPsyETSn7r4RA7Rp5/CVVf56YuysuDPf/aDIzQ7hEgwlKBEUuQcPPGEP3Las8cfLU2a5Lv4RCQ46uITScHq1X4evUGDfHK67jr45BMlJ5HaoAQlUg3FxfDYY/DNb8L06dC6tb89+/jx0Cp5Dn8RCYS6+ESqsHgx/PrXfsJX8EPJH30Ujjkm3LhE6jsdQYlUIB6HoUP9sPE5c+Doo/0s5C++qOQkUheUoESSFBXBk0/6mwk+/LAfFDFoEPznP3DppWFHJ5I51MUnkuCcn/1h+HCfjADOO88nqa5dw41NJBPpCEoynnPw1lt+JN4ll/jk1LEjPPccvP22kpNIWHQEJRnLOZgxA+67D957z6/Lzoa77oJf/cpP9ioi4VGCkoxTWAgvvQT33+9ngQA/ueutt8LNN0Pz5uHGJyKeEpRkjK1b/eCHxx6DNWv8uqOPhttug4EDoUWLcOMTkYMpQUm95hz861/+VuvPPONnfwDo1MkPIb/+emjSJNwYRaR8SlBSL331FUyY4G+zvmTJ1+t79oSbboILL9QdbkWiTglK6o1du/ygh6ef9tMRFRX59dnZ8ItfwC9/CZ07hxujiFSfEpSktZ07/e3Vp0zxSamkCy8rCy6+GG64wR81NWoUbpwikjolKEk769bBrFkwdSrMnOlvGlji+9+Hfv38jQOPOiq8GEWk5pSgJPL27fPXKc2c6ZeFC78uM/O3Vr/sMn+Rbfv24cUpIsFSgpLI2bcPPvoIZs/2y5w5/vxSiebN4fzzoVcv342niVtF6iclKAndhg0+IX3wAbz7rh8WXrrbDqBLF38uqWdP+MEPoHHjcGIVkbqjBCV1auNG30U3b55PSh995O9Sm6xLFzj3XL+ccw4ce2zdxyoi4VKCklqxa5e/0d/ChbBokf+5cKFPUMlatIDu3eG73/VHRz/4ARxxRN3HLCLRogQlh2zfPli5Ej77zC/Ll8OHH57Bli2wapWfxSFZy5b+6KhbN/je9/zSuTM0bFj38YtItClBSbmcg+3b/Zx1a9b4brjSj1et8j+Li5Nf2Rbw1yGdeip861t+6dLF/zzhBD/yTkSkKkpQGaawEDZt8gMTNm70P0uWjRv9FEFr1/rkk59f+bYaNIATT/R3nj3lFDj5ZNiz599ccskZnHiiblchIjWjBJWGnPMzJuzYAdu2+Vm6t22r+vHmzbBlS/ldb+Vp1gw6dIDjj/dL8uPyklAstlXTCYlIIAJJUGY2BOgPfAt41jnXP4jtpqviYp9A9u49+Gdl6/Lz/bJzZ+U/S5ayXWvVYwZHHulnWcjO/nop/Xv79j4JtWmj7jgRCU9QR1DrgRHAhUDTVF64bx8sW+Yn9iy9FBeXXRfU+sJC2L8fCgoO/ln68bp1p/HII2XXV/S4oODrhLN/f0CtWokmTfyAg7ZtfSIpWSr7vV07v2TpuFlE0oC56vb3VGdjZiOA9qkcQZm1dNA9aW0/YDCwG+hdzqv6J5bNwGXllA8CLgfWANeWU34rcBGwFBhYTvlwoAeQBwwtp/w+4CzgfWBYOeWjaNq0Gw0bvklBwQgaNOCgpUuXJzjiiM5s2/Yqn332EA0a+FFsJcuNN06gQ4fjyct7njfeGHNQWcOGMGXKFI4+uh3jx49n/PjxZWqfPn06zZo1Y/To0UyePLlMeSwWA2DkyJFMmzbtoLKmTZsyY8YMAP7whz/w1ltvHVR+xBFH8OKLLwJw5513Mnfu3IPKGzVqxBtvvAHA0KFDySu5ZW1Cp06dGDt2LAADBgxg2bJlB5V369aNUaNGAXDNNdewdu3ag8rPPPNM7r//fgAuvfRStmzZclD5j370I+666y4AevXqxZ6S2WMT+vTpw2233QZAbm4uyfr168fgwYPZvXs3vXuX3ff69+9P//792bx5M5ddVnbfGzRoEJdffjlr1qzh2mvL7nu33norF110EUuXLmXgwIHk5eVRWFhITk4OAMOHD6dHjx7k5eUxdGjZfe++++7jrLPO4v3332fYsLL73qhRo+jWrRtvvvkmI0aMKFP+xBNP0LlzZ1599VUeeuihMuUTJkzg+OOP5/nnn2fMmDFlyqdMmUK7duHve1dffTXr1q07qLx9+/ZMnDgR0L5X3r53wQUXMGzYsAP7XrIw97133nnnY+dcTvJrQvkubWYDgAH+t+YcdlhxoivJYQYtW+6lTZudwC7Wri1MvObr7qZ27fLJzt5CUdEWli3bf2B9yTaOPz7Occd9yb59G1iwoAAzV6ocTj11Ex07rmLXrrXMnbsXM3dg+2aOs89eRfv288nPX8msWbsOrC95zs9+toROnRqxcuV/eOmlHQfWN2jgaNAAhgyZxymnxPn44wVMmBAv8/4HDvyADh2+5P33F7JzZ9nyk06ay1FHrWDp0sVA/MCRX4kPPniP1q1bs2TJEuLxsq+fPXs2TZo0YdmyZeWWl3xIrFixokz5nj17DpSvXLmyTHlxcfGB8tWrV5cpb9OmzYHytWvXlilfv379gfL169eXKV+7du2B8g0bNpQpX7169YHyTZs2seUqZRIAAAX6SURBVGPHjoPKV65ceaB869at7EuakmLFihUHystrm2XLlhGLxdi7d2+55UuWLCEWi7F9+/ZyyxcvXkwsFmPjxo3lli9cuJCWLVseaLvCwkKccweeu2DBArKysli+fHm5r58/fz4FBQUsWrSo3PJ58+YRj8dZsGBBueUffPABX375JQsXLiy3fO7cuaxYsYLFixeXW/7ee9HY9woKCsqUN2rUSPteJfve3r17icVi5f7fQvj7XnlCP4LKyclx8+bNCyyGoMRisXK/5Ujl1G6pyc3NJR6Pl/m2L5XTfpa6KLeZmZV7BFXlPUXNLGZmroJlTu2EKyIima7KLj7nXG4dxCEiInKQoIaZZyW21RBoaGZNgELnXGEQ2xcRkcxTZRdfNQ0H9gB3ANckHg8PaNsiIpKBAjmCcs7dA9wTxLZEREQguCMoERGRQClBiYhIJClBiYhIJClBiYhIJClBiYhIJClBiYhIJClBiYhIJClBiYhIJClBiYhIJClBiYhIJClBiYhIJClBiYhIJClBiYhIJClBiYhIJClBiYhIJClBiYhIJClBiYhIJClBiYhIJClBiYhIJClBiYhIJClBiYhIJClBiYhIJClBiYhIJClBiYhIJClBiYhIJClBiYhIJClBiYhIJClBiYhIJClBiYhIJClBiYhIJClBiYhIJClBiYhIJNU4QZlZYzMbZ2arzGynmeWZWa8gghMRkcwVxBFUFrAGOA9oDQwHJptZxwC2LSIiGSqrphtwzu0C7im1apqZrQS6A1/UdPsiIpKZapygkplZNtAJWFzJcwYAAwCys7OJxWJBh1Fj+fn5kYwr6tRuqYnH4xQVFanNUqT9LHXp2GbmnAtuY2aNgBnACufcwOq8Jicnx82bNy+wGIISi8XIzc0NO4y0o3ZLTW5uLvF4nLy8vLBDSSvaz1IX5TYzs4+dcznJ66s8B2VmMTNzFSxzSj2vATABKACGBBq9iIhknCq7+JxzuVU9x8wMGAdkA72dc/trHpqIiGSyoM5BjQFOA3o45/YEtE0REclgQVwHdQIwEOgGfGVm+Ynl6hpHJyIiGSuIYearAAsgFhERkQM01ZGIiESSEpSIiERSoNdBHVIAZpuAVaEGUb52wOawg0hDarfUqc1SpzZLXZTb7ATn3JHJK0NPUFFlZvPKu3BMKqd2S53aLHVqs9SlY5upi09ERCJJCUpERCJJCapiY8MOIE2p3VKnNkud2ix1addmOgclIiKRpCMoERGJJCUoERGJJCUoERGJJCWoajKzU8xsr5lNDDuWKDOzxmY2zsxWmdlOM8szs15hxxVFZtbWzF42s12J9roq7JiiTPtWzaTjZ5gSVPU9BnwUdhBpIAtYA5wHtAaGA5PNrGOIMUXVY/gbfGYDVwNjzOyb4YYUadq3aibtPsOUoKrBzK4A4sBbYccSdc65Xc65e5xzXzjnip1z04CVQPewY4sSM2sOXArc5ZzLd87NAaYC14YbWXRp3zp06foZpgRVBTNrBdwL3BJ2LOnIzLKBTsDisGOJmE5AoXNuWal1CwAdQVWT9q3qSefPMCWoqv0BGOecWxt2IOnGzBoBk4C/O+eWhB1PxLQAdiSt2w60DCGWtKN9KyVp+xmW0QnKzGJm5ipY5phZN6AH8JewY42Kqtqs1PMaABPw51iGhBZwdOUDrZLWtQJ2hhBLWtG+VX3p/hlW4zvqpjPnXG5l5WY2FOgIrDYz8N96G5rZ6c6579R6gBFUVZsBmG+scfiT/72dc/trO640tAzIMrNTnHOfJdZ1Rd1VldK+lbJc0vgzTFMdVcLMmnHwt9zb8H/sQc65TaEElQbM7HGgG9DDOZcfdjxRZWbPAQ64Ed9e04GznHNKUhXQvpWadP8My+gjqKo453YDu0t+N7N8YG86/GHDYmYnAAOBfcBXiW9tAAOdc5NCCyyaBgNPARuBLfgPDSWnCmjfSl26f4bpCEpERCIpowdJiIhIdClBiYhIJClBiYhIJClBiYhIJClBiYhIJClBiYhIJClBiYhIJClBiYhIJP1/WSNimRllS14AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, elu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1, -1], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"ELU activation function ($\\alpha=1$)\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "save_fig(\"elu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing ELU in TensorFlow is trivial, just specify the activation function when building each layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.elu, name=\"hidden1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SELU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This activation function was proposed in this great paper by Gnter Klambauer, Thomas Unterthiner and Andreas Mayr, \n",
    "published in June 2017. During training, a neural network composed exclusively of a stack of dense layers using \n",
    "the SELU activation function and LeCun initialization will self-normalize: the output of each layer will tend to \n",
    "preserve the same mean and variance during training, which solves the vanishing/exploding gradients problem. \n",
    "As a result, this activation function outperforms the other activation functions very significantly for such \n",
    "neural nets, so you should really try it out. Unfortunately, the self-normalizing property of the SELU \n",
    "activation function is easily broken: you cannot use 1 or 2 regularization, regular dropout, max-norm, \n",
    "skip connections or other non-sequential topologies (so recurrent neural networks \n",
    "won't self-normalize). However, in practice it works quite well with sequential CNNs. If you break \n",
    "self-normalization, SELU will not necessarily outperform other activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import erfc\n",
    "\n",
    "# alpha and scale to self normalize with mean 0 and standard deviation 1\n",
    "# (see equation 14 in the paper):\n",
    "alpha_0_1 = -np.sqrt(2 / np.pi) / (erfc(1/np.sqrt(2)) * np.exp(1/2) - 1)\n",
    "scale_0_1 = (1 - erfc(1 / np.sqrt(2)) * np.sqrt(np.e)) * np.sqrt(2 * np.pi) * (2 * erfc(np.sqrt(2))*np.e**2 + np.pi*erfc(1/np.sqrt(2))**2*np.e - 2*(2+np.pi)*erfc(1/np.sqrt(2))*np.sqrt(np.e)+np.pi+2)**(-1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selu(z, scale=scale_0_1, alpha=alpha_0_1):\n",
    "    return scale * elu(z, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure selu_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, selu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1.758, -1.758], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"SELU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "save_fig(\"selu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the SELU hyperparameters (scale and alpha) are tuned in such a way that the mean output of each neuron remains close to 0, and the standard deviation remains close to 1 (assuming the inputs are standardized with mean 0 and standard deviation 1 too). Using this activation function, even a 1,000 layer deep neural network preserves roughly mean 0 and standard deviation 1 across all layers, avoiding the exploding/vanishing gradients problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: mean -0.00, std deviation 1.00\n",
      "Layer 100: mean 0.02, std deviation 0.96\n",
      "Layer 200: mean 0.01, std deviation 0.90\n",
      "Layer 300: mean -0.02, std deviation 0.92\n",
      "Layer 400: mean 0.05, std deviation 0.89\n",
      "Layer 500: mean 0.01, std deviation 0.93\n",
      "Layer 600: mean 0.02, std deviation 0.92\n",
      "Layer 700: mean -0.02, std deviation 0.90\n",
      "Layer 800: mean 0.05, std deviation 0.83\n",
      "Layer 900: mean 0.02, std deviation 1.00\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "Z = np.random.normal(size=(500, 100)) # standardized inputs\n",
    "for layer in range(1000):\n",
    "    W = np.random.normal(size=(100, 100), scale=np.sqrt(1 / 100)) # LeCun initialization\n",
    "    Z = selu(np.dot(Z, W))\n",
    "    means = np.mean(Z, axis=0).mean()\n",
    "    stds = np.std(Z, axis=0).mean()\n",
    "    if layer % 100 == 0:\n",
    "        print(\"Layer {}: mean {:.2f}, std deviation {:.2f}\".format(layer, means, stds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tf.nn.selu() function was added in TensorFlow 1.4. For earlier versions, you can use the following implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selu(z, scale=alpha_0_1, alpha=scale_0_1):\n",
    "    return scale * tf.where(z >= 0.0, z, alpha * tf.nn.elu(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the SELU activation function cannot be used along with regular Dropout (this would cancel the SELU activation function's self-normalizing property). Fortunately, there is a Dropout variant called Alpha Dropout proposed in the same paper. It is available in tf.contrib.nn.alpha_dropout() since TF 1.4 (or check out this implementation by the Institute of Bioinformatics, Johannes Kepler University Linz).\n",
    "\n",
    "Let's create a neural net for MNIST using the SELU activation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=selu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=selu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "n_epochs = 40\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train it. Do not forget to scale the inputs to mean 0 and standard deviation 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Batch accuracy: 0.94 Validation accuracy: 0.9388\n",
      "5 Batch accuracy: 0.98 Validation accuracy: 0.9634\n",
      "10 Batch accuracy: 1.0 Validation accuracy: 0.9694\n",
      "15 Batch accuracy: 1.0 Validation accuracy: 0.9704\n",
      "20 Batch accuracy: 1.0 Validation accuracy: 0.9692\n",
      "25 Batch accuracy: 1.0 Validation accuracy: 0.969\n",
      "30 Batch accuracy: 1.0 Validation accuracy: 0.9706\n",
      "35 Batch accuracy: 1.0 Validation accuracy: 0.9704\n"
     ]
    }
   ],
   "source": [
    "means = X_train.mean(axis=0, keepdims=True)\n",
    "stds = X_train.std(axis=0, keepdims=True) + 1e-10\n",
    "X_val_scaled = (X_valid - means) / stds\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            X_batch_scaled = (X_batch - means) / stds\n",
    "            sess.run(training_op, feed_dict={X: X_batch_scaled, y: y_batch})\n",
    "        if epoch % 5 == 0:\n",
    "            acc_batch = accuracy.eval(feed_dict={X: X_batch_scaled, y: y_batch})\n",
    "            acc_valid = accuracy.eval(feed_dict={X: X_val_scaled, y: y_valid})\n",
    "            print(epoch, \"Batch accuracy:\", acc_batch, \"Validation accuracy:\", acc_valid)\n",
    "\n",
    "    save_path = saver.save(sess, r\"./tf_logs/SELU/my_model_final.ckpt\")\n",
    "    file_writer = tf.summary.FileWriter(r\"./tf_logs/SELU\", tf.get_default_graph())\n",
    "    file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the book uses tensorflow.contrib.layers.batch_norm() rather than tf.layers.batch_normalization() (which did not exist when this chapter was written). It is now preferable to use tf.layers.batch_normalization(), because anything in the contrib module may change or be deleted without notice. Instead of using the batch_norm() function as a regularizer parameter to the fully_connected() function, we now use batch_normalization() and we explicitly create a distinct layer. The parameters are a bit different, in particular:\n",
    "\n",
    "decay is renamed to momentum,\n",
    "is_training is renamed to training,\n",
    "updates_collections is removed: the update operations needed by batch normalization are added to the UPDATE_OPS collection and you need to explicity run these operations during training (see the execution phase below),\n",
    "we don't need to specify scale=True, as that is the default.\n",
    "Also note that in order to run batch norm just before each hidden layer's activation function, we apply the ELU activation function manually, right after the batch norm layer.\n",
    "\n",
    "Note: since the tf.layers.dense() function is incompatible with tf.contrib.layers.arg_scope() (which is used in the book), we now use python's functools.partial() function instead. It makes it easy to create a my_dense_layer() function that just calls tf.layers.dense() with the desired parameters automatically set (unless they are overridden when calling my_dense_layer()). As you can see, the code remains very similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-32-2f36d39a8af9>:15: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\")\n",
    "bn1 = tf.layers.batch_normalization(hidden1, training=training, momentum=0.9)\n",
    "bn1_act = tf.nn.elu(bn1)\n",
    "\n",
    "hidden2 = tf.layers.dense(bn1_act, n_hidden2, name=\"hidden2\")\n",
    "bn2 = tf.layers.batch_normalization(hidden2, training=training, momentum=0.9)\n",
    "bn2_act = tf.nn.elu(bn2)\n",
    "\n",
    "logits_before_bn = tf.layers.dense(bn2_act, n_outputs, name=\"outputs\")\n",
    "logits = tf.layers.batch_normalization(logits_before_bn, training=training,\n",
    "                                       momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid repeating the same parameters over and over again, we can use Python's partial() function:\n",
    "https://docs.python.org/3.6/library/functools.html?highlight=partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "my_batch_norm_layer = partial(tf.layers.batch_normalization,\n",
    "                              training=training, momentum=0.9)\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\")\n",
    "bn1 = my_batch_norm_layer(hidden1)\n",
    "bn1_act = tf.nn.elu(bn1)\n",
    "hidden2 = tf.layers.dense(bn1_act, n_hidden2, name=\"hidden2\")\n",
    "bn2 = my_batch_norm_layer(hidden2)\n",
    "bn2_act = tf.nn.elu(bn2)\n",
    "logits_before_bn = tf.layers.dense(bn2_act, n_outputs, name=\"outputs\")\n",
    "logits = my_batch_norm_layer(logits_before_bn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a neural net for MNIST, using the ELU activation function and Batch Normalization at each layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "batch_norm_momentum = 0.9\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    he_init = tf.variance_scaling_initializer()\n",
    "\n",
    "    my_batch_norm_layer = partial(\n",
    "            tf.layers.batch_normalization,\n",
    "            training=training,\n",
    "            momentum=batch_norm_momentum)\n",
    "\n",
    "    my_dense_layer = partial(\n",
    "            tf.layers.dense,\n",
    "            kernel_initializer=he_init)\n",
    "\n",
    "    hidden1 = my_dense_layer(X, n_hidden1, name=\"hidden1\")\n",
    "    bn1 = tf.nn.elu(my_batch_norm_layer(hidden1))\n",
    "    hidden2 = my_dense_layer(bn1, n_hidden2, name=\"hidden2\")\n",
    "    bn2 = tf.nn.elu(my_batch_norm_layer(hidden2))\n",
    "    logits_before_bn = my_dense_layer(bn2, n_outputs, name=\"outputs\")\n",
    "    logits = my_batch_norm_layer(logits_before_bn)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: since we are using tf.layers.batch_normalization() rather than tf.contrib.layers.batch_norm() (as in the book), we need to explicitly run the extra update operations needed by batch normalization (sess.run([training_op, extra_update_ops],...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.8952\n",
      "1 Validation accuracy: 0.9202\n",
      "2 Validation accuracy: 0.9318\n",
      "3 Validation accuracy: 0.9422\n",
      "4 Validation accuracy: 0.9468\n",
      "5 Validation accuracy: 0.954\n",
      "6 Validation accuracy: 0.9568\n",
      "7 Validation accuracy: 0.96\n",
      "8 Validation accuracy: 0.962\n",
      "9 Validation accuracy: 0.9638\n",
      "10 Validation accuracy: 0.9662\n",
      "11 Validation accuracy: 0.9682\n",
      "12 Validation accuracy: 0.9672\n",
      "13 Validation accuracy: 0.9696\n",
      "14 Validation accuracy: 0.9706\n",
      "15 Validation accuracy: 0.9704\n",
      "16 Validation accuracy: 0.9718\n",
      "17 Validation accuracy: 0.9726\n",
      "18 Validation accuracy: 0.9738\n",
      "19 Validation accuracy: 0.9742\n"
     ]
    }
   ],
   "source": [
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run([training_op, extra_update_ops],\n",
    "                     feed_dict={training: True, X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, r\"./tf_logs/BatchNormalization/my_model_final.ckpt\")\n",
    "    file_writer = tf.summary.FileWriter(r\"./tf_logs/BatchNormalization\", tf.get_default_graph())\n",
    "    file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What!? That's not a great accuracy for MNIST. Of course, if you train for longer it will get much better accuracy, but with such a shallow network, Batch Norm and ELU are unlikely to have very positive impact: they shine mostly for much deeper nets.\n",
    "\n",
    "Note that you could also make the training operation depend on the update operations:\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(extra_update_ops):\n",
    "        training_op = optimizer.minimize(loss)\n",
    "This way, you would just have to evaluate the training_op during training, TensorFlow would automatically run the update operations as well:\n",
    "\n",
    "sess.run(training_op, feed_dict={training: True, X: X_batch, y: y_batch})\n",
    "One more thing: notice that the list of trainable variables is shorter than the list of all global variables. This is because the moving averages are non-trainable variables. If you want to reuse a pretrained neural network (see below), you must not forget these non-trainable variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more thing: notice that the list of trainable variables is shorter than the list of all global variables. This is because the moving averages are non-trainable variables. If you want to reuse a pretrained neural network (see below), you must not forget these non-trainable variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hidden1/kernel:0',\n",
       " 'hidden1/bias:0',\n",
       " 'batch_normalization/gamma:0',\n",
       " 'batch_normalization/beta:0',\n",
       " 'hidden2/kernel:0',\n",
       " 'hidden2/bias:0',\n",
       " 'batch_normalization_1/gamma:0',\n",
       " 'batch_normalization_1/beta:0',\n",
       " 'outputs/kernel:0',\n",
       " 'outputs/bias:0',\n",
       " 'batch_normalization_2/gamma:0',\n",
       " 'batch_normalization_2/beta:0']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.name for v in tf.trainable_variables()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hidden1/kernel:0',\n",
       " 'hidden1/bias:0',\n",
       " 'batch_normalization/gamma:0',\n",
       " 'batch_normalization/beta:0',\n",
       " 'batch_normalization/moving_mean:0',\n",
       " 'batch_normalization/moving_variance:0',\n",
       " 'hidden2/kernel:0',\n",
       " 'hidden2/bias:0',\n",
       " 'batch_normalization_1/gamma:0',\n",
       " 'batch_normalization_1/beta:0',\n",
       " 'batch_normalization_1/moving_mean:0',\n",
       " 'batch_normalization_1/moving_variance:0',\n",
       " 'outputs/kernel:0',\n",
       " 'outputs/bias:0',\n",
       " 'batch_normalization_2/gamma:0',\n",
       " 'batch_normalization_2/beta:0',\n",
       " 'batch_normalization_2/moving_mean:0',\n",
       " 'batch_normalization_2/moving_variance:0']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.name for v in tf.global_variables()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Clipping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a simple neural net for MNIST and add gradient clipping. The first part is the same as earlier (except we added a few more layers to demonstrate reusing pretrained models, see below):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_hidden3 = 50\n",
    "n_hidden4 = 50\n",
    "n_hidden5 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\")\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\")\n",
    "    hidden5 = tf.layers.dense(hidden4, n_hidden5, activation=tf.nn.relu, name=\"hidden5\")\n",
    "    logits = tf.layers.dense(hidden5, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we apply gradient clipping. For this, we need to get the gradients, use the clip_by_value() function to clip them, then apply them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1.0\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "capped_gvs = [(tf.clip_by_value(grad, -threshold, threshold), var)\n",
    "              for grad, var in grads_and_vars]\n",
    "training_op = optimizer.apply_gradients(capped_gvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rest is the same as usual:\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.288\n",
      "1 Validation accuracy: 0.7942\n",
      "2 Validation accuracy: 0.8796\n",
      "3 Validation accuracy: 0.906\n",
      "4 Validation accuracy: 0.9164\n",
      "5 Validation accuracy: 0.9216\n",
      "6 Validation accuracy: 0.929\n",
      "7 Validation accuracy: 0.9356\n",
      "8 Validation accuracy: 0.9382\n",
      "9 Validation accuracy: 0.9414\n",
      "10 Validation accuracy: 0.9454\n",
      "11 Validation accuracy: 0.9472\n",
      "12 Validation accuracy: 0.9478\n",
      "13 Validation accuracy: 0.953\n",
      "14 Validation accuracy: 0.9566\n",
      "15 Validation accuracy: 0.9566\n",
      "16 Validation accuracy: 0.9576\n",
      "17 Validation accuracy: 0.959\n",
      "18 Validation accuracy: 0.962\n",
      "19 Validation accuracy: 0.9618\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "    save_path = saver.save(sess, r\"./tf_logs/GradientClipping/my_model_final.ckpt\")\n",
    "    file_writer = tf.summary.FileWriter(r\"./tf_logs/GradientClipping\", tf.get_default_graph())\n",
    "    file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reusing Pretrained Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reusing a TensorFlow Model\n",
    "First you need to load the graph's structure. The import_meta_graph() function does just that, loading the graph's operations into the default graph, and returning a Saver that you can then use to restore the model's state. Note that by default, a Saver saves the structure of the graph into a .meta file, so that's the file you should load:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.import_meta_graph(\"./tf_logs/GradientClipping/my_model_final.ckpt.meta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you need to get a handle on all the operations you will need for training. If you don't know the graph's structure, you can list all the operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      "y\n",
      "hidden1/kernel/Initializer/random_uniform/shape\n",
      "hidden1/kernel/Initializer/random_uniform/min\n",
      "hidden1/kernel/Initializer/random_uniform/max\n",
      "hidden1/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden1/kernel/Initializer/random_uniform/sub\n",
      "hidden1/kernel/Initializer/random_uniform/mul\n",
      "hidden1/kernel/Initializer/random_uniform\n",
      "hidden1/kernel\n",
      "hidden1/kernel/Assign\n",
      "hidden1/kernel/read\n",
      "hidden1/bias/Initializer/zeros\n",
      "hidden1/bias\n",
      "hidden1/bias/Assign\n",
      "hidden1/bias/read\n",
      "dnn/hidden1/MatMul\n",
      "dnn/hidden1/BiasAdd\n",
      "dnn/hidden1/Relu\n",
      "hidden2/kernel/Initializer/random_uniform/shape\n",
      "hidden2/kernel/Initializer/random_uniform/min\n",
      "hidden2/kernel/Initializer/random_uniform/max\n",
      "hidden2/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden2/kernel/Initializer/random_uniform/sub\n",
      "hidden2/kernel/Initializer/random_uniform/mul\n",
      "hidden2/kernel/Initializer/random_uniform\n",
      "hidden2/kernel\n",
      "hidden2/kernel/Assign\n",
      "hidden2/kernel/read\n",
      "hidden2/bias/Initializer/zeros\n",
      "hidden2/bias\n",
      "hidden2/bias/Assign\n",
      "hidden2/bias/read\n",
      "dnn/hidden2/MatMul\n",
      "dnn/hidden2/BiasAdd\n",
      "dnn/hidden2/Relu\n",
      "hidden3/kernel/Initializer/random_uniform/shape\n",
      "hidden3/kernel/Initializer/random_uniform/min\n",
      "hidden3/kernel/Initializer/random_uniform/max\n",
      "hidden3/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden3/kernel/Initializer/random_uniform/sub\n",
      "hidden3/kernel/Initializer/random_uniform/mul\n",
      "hidden3/kernel/Initializer/random_uniform\n",
      "hidden3/kernel\n",
      "hidden3/kernel/Assign\n",
      "hidden3/kernel/read\n",
      "hidden3/bias/Initializer/zeros\n",
      "hidden3/bias\n",
      "hidden3/bias/Assign\n",
      "hidden3/bias/read\n",
      "dnn/hidden3/MatMul\n",
      "dnn/hidden3/BiasAdd\n",
      "dnn/hidden3/Relu\n",
      "hidden4/kernel/Initializer/random_uniform/shape\n",
      "hidden4/kernel/Initializer/random_uniform/min\n",
      "hidden4/kernel/Initializer/random_uniform/max\n",
      "hidden4/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden4/kernel/Initializer/random_uniform/sub\n",
      "hidden4/kernel/Initializer/random_uniform/mul\n",
      "hidden4/kernel/Initializer/random_uniform\n",
      "hidden4/kernel\n",
      "hidden4/kernel/Assign\n",
      "hidden4/kernel/read\n",
      "hidden4/bias/Initializer/zeros\n",
      "hidden4/bias\n",
      "hidden4/bias/Assign\n",
      "hidden4/bias/read\n",
      "dnn/hidden4/MatMul\n",
      "dnn/hidden4/BiasAdd\n",
      "dnn/hidden4/Relu\n",
      "hidden5/kernel/Initializer/random_uniform/shape\n",
      "hidden5/kernel/Initializer/random_uniform/min\n",
      "hidden5/kernel/Initializer/random_uniform/max\n",
      "hidden5/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden5/kernel/Initializer/random_uniform/sub\n",
      "hidden5/kernel/Initializer/random_uniform/mul\n",
      "hidden5/kernel/Initializer/random_uniform\n",
      "hidden5/kernel\n",
      "hidden5/kernel/Assign\n",
      "hidden5/kernel/read\n",
      "hidden5/bias/Initializer/zeros\n",
      "hidden5/bias\n",
      "hidden5/bias/Assign\n",
      "hidden5/bias/read\n",
      "dnn/hidden5/MatMul\n",
      "dnn/hidden5/BiasAdd\n",
      "dnn/hidden5/Relu\n",
      "outputs/kernel/Initializer/random_uniform/shape\n",
      "outputs/kernel/Initializer/random_uniform/min\n",
      "outputs/kernel/Initializer/random_uniform/max\n",
      "outputs/kernel/Initializer/random_uniform/RandomUniform\n",
      "outputs/kernel/Initializer/random_uniform/sub\n",
      "outputs/kernel/Initializer/random_uniform/mul\n",
      "outputs/kernel/Initializer/random_uniform\n",
      "outputs/kernel\n",
      "outputs/kernel/Assign\n",
      "outputs/kernel/read\n",
      "outputs/bias/Initializer/zeros\n",
      "outputs/bias\n",
      "outputs/bias/Assign\n",
      "outputs/bias/read\n",
      "dnn/outputs/MatMul\n",
      "dnn/outputs/BiasAdd\n",
      "loss/SparseSoftmaxCrossEntropyWithLogits/Shape\n",
      "loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\n",
      "loss/Const\n",
      "loss/loss\n",
      "gradients/Shape\n",
      "gradients/grad_ys_0\n",
      "gradients/Fill\n",
      "gradients/loss/loss_grad/Reshape/shape\n",
      "gradients/loss/loss_grad/Reshape\n",
      "gradients/loss/loss_grad/Shape\n",
      "gradients/loss/loss_grad/Tile\n",
      "gradients/loss/loss_grad/Shape_1\n",
      "gradients/loss/loss_grad/Shape_2\n",
      "gradients/loss/loss_grad/Const\n",
      "gradients/loss/loss_grad/Prod\n",
      "gradients/loss/loss_grad/Const_1\n",
      "gradients/loss/loss_grad/Prod_1\n",
      "gradients/loss/loss_grad/Maximum/y\n",
      "gradients/loss/loss_grad/Maximum\n",
      "gradients/loss/loss_grad/floordiv\n",
      "gradients/loss/loss_grad/Cast\n",
      "gradients/loss/loss_grad/truediv\n",
      "gradients/zeros_like\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul\n",
      "gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/outputs/MatMul_grad/MatMul\n",
      "gradients/dnn/outputs/MatMul_grad/MatMul_1\n",
      "gradients/dnn/outputs/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/outputs/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden5/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden5/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden5/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden5/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden5/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden5/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden4/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden4/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden4/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden4/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden4/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden4/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden3/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden3/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden3/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden3/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden3/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden3/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden2/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden2/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden2/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden2/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden1/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden1/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden1/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden1/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1\n",
      "clip_by_value/Minimum/y\n",
      "clip_by_value/Minimum\n",
      "clip_by_value/y\n",
      "clip_by_value\n",
      "clip_by_value_1/Minimum/y\n",
      "clip_by_value_1/Minimum\n",
      "clip_by_value_1/y\n",
      "clip_by_value_1\n",
      "clip_by_value_2/Minimum/y\n",
      "clip_by_value_2/Minimum\n",
      "clip_by_value_2/y\n",
      "clip_by_value_2\n",
      "clip_by_value_3/Minimum/y\n",
      "clip_by_value_3/Minimum\n",
      "clip_by_value_3/y\n",
      "clip_by_value_3\n",
      "clip_by_value_4/Minimum/y\n",
      "clip_by_value_4/Minimum\n",
      "clip_by_value_4/y\n",
      "clip_by_value_4\n",
      "clip_by_value_5/Minimum/y\n",
      "clip_by_value_5/Minimum\n",
      "clip_by_value_5/y\n",
      "clip_by_value_5\n",
      "clip_by_value_6/Minimum/y\n",
      "clip_by_value_6/Minimum\n",
      "clip_by_value_6/y\n",
      "clip_by_value_6\n",
      "clip_by_value_7/Minimum/y\n",
      "clip_by_value_7/Minimum\n",
      "clip_by_value_7/y\n",
      "clip_by_value_7\n",
      "clip_by_value_8/Minimum/y\n",
      "clip_by_value_8/Minimum\n",
      "clip_by_value_8/y\n",
      "clip_by_value_8\n",
      "clip_by_value_9/Minimum/y\n",
      "clip_by_value_9/Minimum\n",
      "clip_by_value_9/y\n",
      "clip_by_value_9\n",
      "clip_by_value_10/Minimum/y\n",
      "clip_by_value_10/Minimum\n",
      "clip_by_value_10/y\n",
      "clip_by_value_10\n",
      "clip_by_value_11/Minimum/y\n",
      "clip_by_value_11/Minimum\n",
      "clip_by_value_11/y\n",
      "clip_by_value_11\n",
      "GradientDescent/learning_rate\n",
      "GradientDescent/update_hidden1/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden1/bias/ApplyGradientDescent\n",
      "GradientDescent/update_hidden2/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden2/bias/ApplyGradientDescent\n",
      "GradientDescent/update_hidden3/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden3/bias/ApplyGradientDescent\n",
      "GradientDescent/update_hidden4/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden4/bias/ApplyGradientDescent\n",
      "GradientDescent/update_hidden5/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden5/bias/ApplyGradientDescent\n",
      "GradientDescent/update_outputs/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_outputs/bias/ApplyGradientDescent\n",
      "GradientDescent\n",
      "eval/in_top_k/InTopKV2/k\n",
      "eval/in_top_k/InTopKV2\n",
      "eval/Cast\n",
      "eval/Const\n",
      "eval/accuracy\n",
      "init\n",
      "save/filename/input\n",
      "save/filename\n",
      "save/Const\n",
      "save/SaveV2/tensor_names\n",
      "save/SaveV2/shape_and_slices\n",
      "save/SaveV2\n",
      "save/control_dependency\n",
      "save/RestoreV2/tensor_names\n",
      "save/RestoreV2/shape_and_slices\n",
      "save/RestoreV2\n",
      "save/Assign\n",
      "save/Assign_1\n",
      "save/Assign_2\n",
      "save/Assign_3\n",
      "save/Assign_4\n",
      "save/Assign_5\n",
      "save/Assign_6\n",
      "save/Assign_7\n",
      "save/Assign_8\n",
      "save/Assign_9\n",
      "save/Assign_10\n",
      "save/Assign_11\n",
      "save/restore_all\n"
     ]
    }
   ],
   "source": [
    "for op in tf.get_default_graph().get_operations():\n",
    "    print(op.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops, that's a lot of operations! you will need to use a FileWriter to save the graph and then visualize it in TensorBoard)\n",
    "start tenssorboard and check graph\n",
    "[i328815@MacPro ~/Documents/Notes_HandsOn_ML]$ tensorboard --logdir tf_logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you know which operations you need, you can get a handle on them using the graph's get_operation_by_name() or get_tensor_by_name() methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "\n",
    "accuracy = tf.get_default_graph().get_tensor_by_name(\"eval/accuracy:0\")\n",
    "\n",
    "training_op = tf.get_default_graph().get_operation_by_name(\"GradientDescent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are the author of the original model, you could make things easier for people who will reuse your model by giving operations very clear names and documenting them. Another approach is to create a collection containing all the important operations that people will want to get a handle on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for op in (X, y, accuracy, training_op):\n",
    "    tf.add_to_collection(\"my_important_ops\", op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This way people who reuse your model will be able to simply write:\n",
    "#X, y, accuracy, training_op = tf.get_collection(\"my_important_ops\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can start a session, restore the model's state and continue training on your data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./tf_logs/GradientClipping/my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./tf_logs/GradientClipping/my_model_final.ckpt\")\n",
    "    # continue training the model..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, let's test this for real!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tf_logs/GradientClipping/my_model_final.ckpt\n",
      "0 Validation accuracy: 0.9642\n",
      "1 Validation accuracy: 0.963\n",
      "2 Validation accuracy: 0.9656\n",
      "3 Validation accuracy: 0.9652\n",
      "4 Validation accuracy: 0.9642\n",
      "5 Validation accuracy: 0.965\n",
      "6 Validation accuracy: 0.9686\n",
      "7 Validation accuracy: 0.9686\n",
      "8 Validation accuracy: 0.9684\n",
      "9 Validation accuracy: 0.9684\n",
      "10 Validation accuracy: 0.9702\n",
      "11 Validation accuracy: 0.9716\n",
      "12 Validation accuracy: 0.9676\n",
      "13 Validation accuracy: 0.97\n",
      "14 Validation accuracy: 0.9706\n",
      "15 Validation accuracy: 0.9724\n",
      "16 Validation accuracy: 0.972\n",
      "17 Validation accuracy: 0.9712\n",
      "18 Validation accuracy: 0.9712\n",
      "19 Validation accuracy: 0.9708\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./tf_logs/GradientClipping/my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./tf_logs/GradientClipping/my_new_model_final.ckpt\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, if you have access to the Python code that built the original graph, you can use it instead of import_meta_graph():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_hidden3 = 50\n",
    "n_hidden4 = 50\n",
    "n_hidden5 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\")\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\")\n",
    "    hidden5 = tf.layers.dense(hidden4, n_hidden5, activation=tf.nn.relu, name=\"hidden5\")\n",
    "    logits = tf.layers.dense(hidden5, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "threshold = 1.0\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "capped_gvs = [(tf.clip_by_value(grad, -threshold, threshold), var)\n",
    "              for grad, var in grads_and_vars]\n",
    "training_op = optimizer.apply_gradients(capped_gvs)\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And continue training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tf_logs/GradientClipping/my_model_final.ckpt\n",
      "0 Validation accuracy: 0.9642\n",
      "1 Validation accuracy: 0.963\n",
      "2 Validation accuracy: 0.9656\n",
      "3 Validation accuracy: 0.9652\n",
      "4 Validation accuracy: 0.9642\n",
      "5 Validation accuracy: 0.965\n",
      "6 Validation accuracy: 0.9686\n",
      "7 Validation accuracy: 0.9686\n",
      "8 Validation accuracy: 0.9684\n",
      "9 Validation accuracy: 0.9684\n",
      "10 Validation accuracy: 0.9702\n",
      "11 Validation accuracy: 0.9716\n",
      "12 Validation accuracy: 0.9676\n",
      "13 Validation accuracy: 0.97\n",
      "14 Validation accuracy: 0.9706\n",
      "15 Validation accuracy: 0.9724\n",
      "16 Validation accuracy: 0.972\n",
      "17 Validation accuracy: 0.9712\n",
      "18 Validation accuracy: 0.9712\n",
      "19 Validation accuracy: 0.9708\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./tf_logs/GradientClipping/my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./tf_logs/GradientClipping/my_new_model_final.ckpt\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general you will want to reuse only the lower layers. If you are using import_meta_graph() it will load the whole graph, but you can simply ignore the parts you do not need. In this example, we add a new 4th hidden layer on top of the pretrained 3rd layer (ignoring the old 4th hidden layer). We also build a new output layer, the loss for this new output, and a new optimizer to minimize it. We also need another saver to save the whole graph (containing both the entire old graph plus the new operations), and an initialization operation to initialize all the new variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_hidden4 = 20  # new layer\n",
    "n_outputs = 10  # new layer\n",
    "\n",
    "saver = tf.train.import_meta_graph(\"./tf_logs/GradientClipping/my_model_final.ckpt.meta\")\n",
    "\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "\n",
    "hidden3 = tf.get_default_graph().get_tensor_by_name(\"dnn/hidden3/Relu:0\")\n",
    "\n",
    "new_hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"new_hidden4\")\n",
    "new_logits = tf.layers.dense(new_hidden4, n_outputs, name=\"new_outputs\")\n",
    "\n",
    "with tf.name_scope(\"new_loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=new_logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"new_eval\"):\n",
    "    correct = tf.nn.in_top_k(new_logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "with tf.name_scope(\"new_train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "new_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can train this new model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tf_logs/GradientClipping/my_model_final.ckpt\n",
      "0 Validation accuracy: 0.9184\n",
      "1 Validation accuracy: 0.9394\n",
      "2 Validation accuracy: 0.949\n",
      "3 Validation accuracy: 0.9526\n",
      "4 Validation accuracy: 0.9556\n",
      "5 Validation accuracy: 0.956\n",
      "6 Validation accuracy: 0.9576\n",
      "7 Validation accuracy: 0.961\n",
      "8 Validation accuracy: 0.9612\n",
      "9 Validation accuracy: 0.9644\n",
      "10 Validation accuracy: 0.965\n",
      "11 Validation accuracy: 0.966\n",
      "12 Validation accuracy: 0.9642\n",
      "13 Validation accuracy: 0.967\n",
      "14 Validation accuracy: 0.9684\n",
      "15 Validation accuracy: 0.9682\n",
      "16 Validation accuracy: 0.97\n",
      "17 Validation accuracy: 0.9674\n",
      "18 Validation accuracy: 0.9694\n",
      "19 Validation accuracy: 0.9704\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    saver.restore(sess, \"./tf_logs/GradientClipping/my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = new_saver.save(sess, \"./tf_logs/GradientClipping/my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have access to the Python code that built the original graph, you can just reuse the parts you need and drop the rest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300 # reused\n",
    "n_hidden2 = 50  # reused\n",
    "n_hidden3 = 50  # reused\n",
    "n_hidden4 = 20  # new!\n",
    "n_outputs = 10  # new!\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")       # reused\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\") # reused\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\") # reused\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\") # new!\n",
    "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\")                         # new!\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, you must create one Saver to restore the pretrained model (giving it the list of variables to restore, or else it will complain that the graphs don't match), and another Saver to save the new model, once it is trained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tf_logs/GradientClipping/my_model_final.ckpt\n",
      "0 Validation accuracy: 0.903\n",
      "1 Validation accuracy: 0.9334\n",
      "2 Validation accuracy: 0.9426\n",
      "3 Validation accuracy: 0.9472\n",
      "4 Validation accuracy: 0.9522\n",
      "5 Validation accuracy: 0.9532\n",
      "6 Validation accuracy: 0.9556\n",
      "7 Validation accuracy: 0.959\n",
      "8 Validation accuracy: 0.9588\n",
      "9 Validation accuracy: 0.9608\n",
      "10 Validation accuracy: 0.962\n",
      "11 Validation accuracy: 0.9618\n",
      "12 Validation accuracy: 0.9638\n",
      "13 Validation accuracy: 0.966\n",
      "14 Validation accuracy: 0.9664\n",
      "15 Validation accuracy: 0.9658\n",
      "16 Validation accuracy: 0.967\n",
      "17 Validation accuracy: 0.9674\n",
      "18 Validation accuracy: 0.9684\n",
      "19 Validation accuracy: 0.9672\n"
     ]
    }
   ],
   "source": [
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                               scope=\"hidden[123]\") # regular expression\n",
    "restore_saver = tf.train.Saver(reuse_vars) # to restore layers 1-3\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./tf_logs/GradientClipping/my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):                                            \n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size): \n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})        \n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})     \n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)                   \n",
    "\n",
    "    save_path = saver.save(sess, \"./tf_logs/GradientClipping/my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reusing Models from Other Frameworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, for each variable we want to reuse, we find its initializer's assignment operation, and we get its second input, which corresponds to the initialization value. When we run the initializer, we replace the initialization values with the ones we want, using a feed_dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 2\n",
    "n_hidden1 = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 61.  83. 105.]]\n"
     ]
    }
   ],
   "source": [
    "original_w = [[1., 2., 3.], [4., 5., 6.]] # Load the weights from the other framework\n",
    "original_b = [7., 8., 9.]                 # Load the biases from the other framework\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "# [...] Build the rest of the model\n",
    "\n",
    "# Get a handle on the assignment nodes for the hidden1 variables\n",
    "graph = tf.get_default_graph()\n",
    "assign_kernel = graph.get_operation_by_name(\"hidden1/kernel/Assign\")\n",
    "assign_bias = graph.get_operation_by_name(\"hidden1/bias/Assign\")\n",
    "init_kernel = assign_kernel.inputs[1]\n",
    "init_bias = assign_bias.inputs[1]\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init, feed_dict={init_kernel: original_w, init_bias: original_b})\n",
    "    # [...] Train the model on your new task\n",
    "    print(hidden1.eval(feed_dict={X: [[10.0, 11.0]]}))  # not shown in the book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the weights variable created by the tf.layers.dense() function is called \"kernel\" (instead of \"weights\" when using the tf.contrib.layers.fully_connected(), as in the book), and the biases variable is called bias instead of biases.\n",
    "\n",
    "Another approach (initially used in the book) would be to create dedicated assignment nodes and dedicated placeholders. This is more verbose and less efficient, but you may find this more explicit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 61.  83. 105.]]\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 2\n",
    "n_hidden1 = 3\n",
    "\n",
    "original_w = [[1., 2., 3.], [4., 5., 6.]] # Load the weights from the other framework\n",
    "original_b = [7., 8., 9.]                 # Load the biases from the other framework\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "# [...] Build the rest of the model\n",
    "\n",
    "# Get a handle on the variables of layer hidden1\n",
    "with tf.variable_scope(\"\", default_name=\"\", reuse=True):  # root scope\n",
    "    hidden1_weights = tf.get_variable(\"hidden1/kernel\")\n",
    "    hidden1_biases = tf.get_variable(\"hidden1/bias\")\n",
    "\n",
    "# Create dedicated placeholders and assignment nodes\n",
    "original_weights = tf.placeholder(tf.float32, shape=(n_inputs, n_hidden1))\n",
    "original_biases = tf.placeholder(tf.float32, shape=n_hidden1)\n",
    "assign_hidden1_weights = tf.assign(hidden1_weights, original_weights)\n",
    "assign_hidden1_biases = tf.assign(hidden1_biases, original_biases)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    sess.run(assign_hidden1_weights, feed_dict={original_weights: original_w})\n",
    "    sess.run(assign_hidden1_biases, feed_dict={original_biases: original_b})\n",
    "    # [...] Train the model on your new task\n",
    "    print(hidden1.eval(feed_dict={X: [[10.0, 11.0]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we could also get a handle on the variables using get_collection() and specifying the scope:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'hidden1/kernel:0' shape=(2, 3) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden1/bias:0' shape=(3,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"hidden1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we could use the graph's get_tensor_by_name() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'hidden1/kernel:0' shape=(2, 3) dtype=float32_ref>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_default_graph().get_tensor_by_name(\"hidden1/kernel:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'hidden1/bias:0' shape=(3,) dtype=float32_ref>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_default_graph().get_tensor_by_name(\"hidden1/bias:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freezing the Lower Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300 # reused\n",
    "n_hidden2 = 50  # reused\n",
    "n_hidden3 = 50  # reused\n",
    "n_hidden4 = 20  # new!\n",
    "n_outputs = 10  # new!\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")       # reused\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\") # reused\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\") # reused\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\") # new!\n",
    "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\")                         # new!\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"train\"):                                         \n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)     \n",
    "    train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                                   scope=\"hidden[34]|outputs\")\n",
    "    training_op = optimizer.minimize(loss, var_list=train_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tf_logs/GradientClipping/my_model_final.ckpt\n",
      "0 Validation accuracy: 0.8964\n",
      "1 Validation accuracy: 0.9304\n",
      "2 Validation accuracy: 0.9404\n",
      "3 Validation accuracy: 0.9442\n",
      "4 Validation accuracy: 0.948\n",
      "5 Validation accuracy: 0.9506\n",
      "6 Validation accuracy: 0.9508\n",
      "7 Validation accuracy: 0.9536\n",
      "8 Validation accuracy: 0.9556\n",
      "9 Validation accuracy: 0.9566\n",
      "10 Validation accuracy: 0.9558\n",
      "11 Validation accuracy: 0.9568\n",
      "12 Validation accuracy: 0.9568\n",
      "13 Validation accuracy: 0.9572\n",
      "14 Validation accuracy: 0.9586\n",
      "15 Validation accuracy: 0.9578\n",
      "16 Validation accuracy: 0.9574\n",
      "17 Validation accuracy: 0.9596\n",
      "18 Validation accuracy: 0.9594\n",
      "19 Validation accuracy: 0.9602\n"
     ]
    }
   ],
   "source": [
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                               scope=\"hidden[123]\") # regular expression\n",
    "restore_saver = tf.train.Saver(reuse_vars) # to restore layers 1-3\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./tf_logs/GradientClipping/my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./tf_logs/GradientClipping/my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300 # reused\n",
    "n_hidden2 = 50  # reused\n",
    "n_hidden3 = 50  # reused\n",
    "n_hidden4 = 20  # new!\n",
    "n_outputs = 10  # new!\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,\n",
    "                              name=\"hidden1\") # reused frozen\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu,\n",
    "                              name=\"hidden2\") # reused frozen\n",
    "    hidden2_stop = tf.stop_gradient(hidden2)\n",
    "    hidden3 = tf.layers.dense(hidden2_stop, n_hidden3, activation=tf.nn.relu,\n",
    "                              name=\"hidden3\") # reused, not frozen\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu,\n",
    "                              name=\"hidden4\") # new!\n",
    "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\") # new!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training code is exactly the same as earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tf_logs/GradientClipping/my_model_final.ckpt\n",
      "0 Validation accuracy: 0.902\n",
      "1 Validation accuracy: 0.9306\n",
      "2 Validation accuracy: 0.9432\n",
      "3 Validation accuracy: 0.9476\n",
      "4 Validation accuracy: 0.9514\n",
      "5 Validation accuracy: 0.9522\n",
      "6 Validation accuracy: 0.952\n",
      "7 Validation accuracy: 0.9554\n",
      "8 Validation accuracy: 0.9552\n",
      "9 Validation accuracy: 0.9562\n",
      "10 Validation accuracy: 0.957\n",
      "11 Validation accuracy: 0.9552\n",
      "12 Validation accuracy: 0.9572\n",
      "13 Validation accuracy: 0.9578\n",
      "14 Validation accuracy: 0.9578\n",
      "15 Validation accuracy: 0.957\n",
      "16 Validation accuracy: 0.9566\n",
      "17 Validation accuracy: 0.9574\n",
      "18 Validation accuracy: 0.9592\n",
      "19 Validation accuracy: 0.958\n"
     ]
    }
   ],
   "source": [
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                               scope=\"hidden[123]\") # regular expression\n",
    "restore_saver = tf.train.Saver(reuse_vars) # to restore layers 1-3\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./tf_logs/GradientClipping/my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./tf_logs/GradientClipping/my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caching the Frozen Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300 # reused\n",
    "n_hidden2 = 50  # reused\n",
    "n_hidden3 = 50  # reused\n",
    "n_hidden4 = 20  # new!\n",
    "n_outputs = 10  # new!\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,\n",
    "                              name=\"hidden1\") # reused frozen\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu,\n",
    "                              name=\"hidden2\") # reused frozen & cached\n",
    "    hidden2_stop = tf.stop_gradient(hidden2)\n",
    "    hidden3 = tf.layers.dense(hidden2_stop, n_hidden3, activation=tf.nn.relu,\n",
    "                              name=\"hidden3\") # reused, not frozen\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu,\n",
    "                              name=\"hidden4\") # new!\n",
    "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\") # new!\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                               scope=\"hidden[123]\") # regular expression\n",
    "restore_saver = tf.train.Saver(reuse_vars) # to restore layers 1-3\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tf_logs/GradientClipping/my_model_final.ckpt\n",
      "0 Validation accuracy: 0.902\n",
      "1 Validation accuracy: 0.9306\n",
      "2 Validation accuracy: 0.9432\n",
      "3 Validation accuracy: 0.9476\n",
      "4 Validation accuracy: 0.9514\n",
      "5 Validation accuracy: 0.9522\n",
      "6 Validation accuracy: 0.952\n",
      "7 Validation accuracy: 0.9554\n",
      "8 Validation accuracy: 0.9552\n",
      "9 Validation accuracy: 0.9562\n",
      "10 Validation accuracy: 0.957\n",
      "11 Validation accuracy: 0.9552\n",
      "12 Validation accuracy: 0.9572\n",
      "13 Validation accuracy: 0.9578\n",
      "14 Validation accuracy: 0.9578\n",
      "15 Validation accuracy: 0.957\n",
      "16 Validation accuracy: 0.9566\n",
      "17 Validation accuracy: 0.9574\n",
      "18 Validation accuracy: 0.9592\n",
      "19 Validation accuracy: 0.958\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_batches = len(X_train) // batch_size\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./tf_logs/GradientClipping/my_model_final.ckpt\")\n",
    "    \n",
    "    h2_cache = sess.run(hidden2, feed_dict={X: X_train})\n",
    "    h2_cache_valid = sess.run(hidden2, feed_dict={X: X_valid}) # not shown in the book\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        shuffled_idx = np.random.permutation(len(X_train))\n",
    "        hidden2_batches = np.array_split(h2_cache[shuffled_idx], n_batches)\n",
    "        y_batches = np.array_split(y_train[shuffled_idx], n_batches)\n",
    "        for hidden2_batch, y_batch in zip(hidden2_batches, y_batches):\n",
    "            sess.run(training_op, feed_dict={hidden2:hidden2_batch, y:y_batch})\n",
    "\n",
    "        accuracy_val = accuracy.eval(feed_dict={hidden2: h2_cache_valid, # not shown\n",
    "                                                y: y_valid})             # not shown\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)               # not shown\n",
    "\n",
    "    save_path = saver.save(sess, \"./tf_logs/GradientClipping/my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faster Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Momentum optimization\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,\n",
    "                                       momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nesterov Accelerated Gradient\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,\n",
    "                                       momentum=0.9, use_nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaGrad\n",
    "optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSProp\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate,\n",
    "                                      momentum=0.9, decay=0.9, epsilon=1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam Optimization\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning Rate Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"train\"):       \n",
    "    initial_learning_rate = 0.1\n",
    "    decay_steps = 10000\n",
    "    decay_rate = 1/10\n",
    "    global_step = tf.Variable(0, trainable=False, name=\"global_step\")\n",
    "    learning_rate = tf.train.exponential_decay(initial_learning_rate, global_step,\n",
    "                                               decay_steps, decay_rate)\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=0.9)\n",
    "    training_op = optimizer.minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.962\n",
      "1 Validation accuracy: 0.9744\n",
      "2 Validation accuracy: 0.9794\n",
      "3 Validation accuracy: 0.981\n",
      "4 Validation accuracy: 0.9838\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./tf_logs/GradientClipping/my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avoiding Overfitting Through Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1  and  2  regularization\n",
    "Let's implement  1  regularization manually. First, we create the model, as usual (with just one hidden layer this time, for simplicity):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    logits = tf.layers.dense(hidden1, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we get a handle on the layer weights, and we compute the total loss, which is equal to the sum of the usual cross entropy loss and the  1  loss (i.e., the absolute values of the weights):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.get_default_graph().get_tensor_by_name(\"hidden1/kernel:0\")\n",
    "W2 = tf.get_default_graph().get_tensor_by_name(\"outputs/kernel:0\")\n",
    "\n",
    "scale = 0.001 # l1 regularization hyperparameter\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                              logits=logits)\n",
    "    base_loss = tf.reduce_mean(xentropy, name=\"avg_xentropy\")\n",
    "    reg_losses = tf.reduce_sum(tf.abs(W1)) + tf.reduce_sum(tf.abs(W2))\n",
    "    loss = tf.add(base_loss, scale * reg_losses, name=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest is just as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.831\n",
      "1 Validation accuracy: 0.871\n",
      "2 Validation accuracy: 0.8838\n",
      "3 Validation accuracy: 0.8934\n",
      "4 Validation accuracy: 0.8966\n",
      "5 Validation accuracy: 0.8988\n",
      "6 Validation accuracy: 0.9016\n",
      "7 Validation accuracy: 0.9044\n",
      "8 Validation accuracy: 0.9058\n",
      "9 Validation accuracy: 0.906\n",
      "10 Validation accuracy: 0.9068\n",
      "11 Validation accuracy: 0.9054\n",
      "12 Validation accuracy: 0.907\n",
      "13 Validation accuracy: 0.9084\n",
      "14 Validation accuracy: 0.9088\n",
      "15 Validation accuracy: 0.9064\n",
      "16 Validation accuracy: 0.9066\n",
      "17 Validation accuracy: 0.9066\n",
      "18 Validation accuracy: 0.9066\n",
      "19 Validation accuracy: 0.9052\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 200\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./tf_logs/L1L2Regularization/my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can pass a regularization function to the tf.layers.dense() function, which will use it to create operations that will compute the regularization loss, and it adds these operations to the collection of regularization losses. The beginning is the same as above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use Python's partial() function to avoid repeating the same arguments over and over again. Note that we set the kernel_regularizer argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_dense_layer = partial(\n",
    "    tf.layers.dense, activation=tf.nn.relu,\n",
    "    kernel_regularizer=tf.contrib.layers.l1_regularizer(scale))\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = my_dense_layer(X, n_hidden1, name=\"hidden1\")\n",
    "    hidden2 = my_dense_layer(hidden1, n_hidden2, name=\"hidden2\")\n",
    "    logits = my_dense_layer(hidden2, n_outputs, activation=None,\n",
    "                            name=\"outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we must add the regularization losses to the base loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):                                     \n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(  \n",
    "        labels=y, logits=logits)                                \n",
    "    base_loss = tf.reduce_mean(xentropy, name=\"avg_xentropy\")   \n",
    "    reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    loss = tf.add_n([base_loss] + reg_losses, name=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the rest is the same as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.8274\n",
      "1 Validation accuracy: 0.8766\n",
      "2 Validation accuracy: 0.8952\n",
      "3 Validation accuracy: 0.9016\n",
      "4 Validation accuracy: 0.908\n",
      "5 Validation accuracy: 0.9096\n",
      "6 Validation accuracy: 0.9124\n",
      "7 Validation accuracy: 0.9154\n",
      "8 Validation accuracy: 0.9178\n",
      "9 Validation accuracy: 0.919\n",
      "10 Validation accuracy: 0.92\n",
      "11 Validation accuracy: 0.9224\n",
      "12 Validation accuracy: 0.9212\n",
      "13 Validation accuracy: 0.9228\n",
      "14 Validation accuracy: 0.9224\n",
      "15 Validation accuracy: 0.9216\n",
      "16 Validation accuracy: 0.9218\n",
      "17 Validation accuracy: 0.9228\n",
      "18 Validation accuracy: 0.9216\n",
      "19 Validation accuracy: 0.9214\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 200\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./tf_logs/L1L2Regularization//my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the book uses tf.contrib.layers.dropout() rather than tf.layers.dropout() (which did not exist when this chapter was written). It is now preferable to use tf.layers.dropout(), because anything in the contrib module may change or be deleted without notice. The tf.layers.dropout() function is almost identical to the tf.contrib.layers.dropout() function, except for a few minor differences. Most importantly:\n",
    "\n",
    "you must specify the dropout rate (rate) rather than the keep probability (keep_prob), where rate is simply equal to 1 - keep_prob,\n",
    "the is_training parameter is renamed to training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-97-7adcf6dce8db>:4: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n"
     ]
    }
   ],
   "source": [
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "dropout_rate = 0.5  # == 1 - keep_prob\n",
    "X_drop = tf.layers.dropout(X, dropout_rate, training=training)\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X_drop, n_hidden1, activation=tf.nn.relu,\n",
    "                              name=\"hidden1\")\n",
    "    hidden1_drop = tf.layers.dropout(hidden1, dropout_rate, training=training)\n",
    "    hidden2 = tf.layers.dense(hidden1_drop, n_hidden2, activation=tf.nn.relu,\n",
    "                              name=\"hidden2\")\n",
    "    hidden2_drop = tf.layers.dropout(hidden2, dropout_rate, training=training)\n",
    "    logits = tf.layers.dense(hidden2_drop, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=0.9)\n",
    "    training_op = optimizer.minimize(loss)    \n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.9246\n",
      "1 Validation accuracy: 0.9458\n",
      "2 Validation accuracy: 0.9496\n",
      "3 Validation accuracy: 0.9494\n",
      "4 Validation accuracy: 0.9614\n",
      "5 Validation accuracy: 0.9632\n",
      "6 Validation accuracy: 0.9628\n",
      "7 Validation accuracy: 0.9674\n",
      "8 Validation accuracy: 0.9668\n",
      "9 Validation accuracy: 0.9666\n",
      "10 Validation accuracy: 0.969\n",
      "11 Validation accuracy: 0.969\n",
      "12 Validation accuracy: 0.9706\n",
      "13 Validation accuracy: 0.9702\n",
      "14 Validation accuracy: 0.9728\n",
      "15 Validation accuracy: 0.9722\n",
      "16 Validation accuracy: 0.9738\n",
      "17 Validation accuracy: 0.9722\n",
      "18 Validation accuracy: 0.9738\n",
      "19 Validation accuracy: 0.9748\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch, training: True})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "        print(epoch, \"Validation accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./tf_logs/DropOut/my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go back to a plain and simple neural net for MNIST with just 2 hidden layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum)\n",
    "    training_op = optimizer.minimize(loss)    \n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's get a handle on the first hidden layer's weight and create an operation that will compute the clipped weights using the clip_by_norm() function. Then we create an assignment operation to assign the clipped weights to the weights variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1.0\n",
    "weights = tf.get_default_graph().get_tensor_by_name(\"hidden1/kernel:0\")\n",
    "clipped_weights = tf.clip_by_norm(weights, clip_norm=threshold, axes=1)\n",
    "clip_weights = tf.assign(weights, clipped_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this as well for the second hidden layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights2 = tf.get_default_graph().get_tensor_by_name(\"hidden2/kernel:0\")\n",
    "clipped_weights2 = tf.clip_by_norm(weights2, clip_norm=threshold, axes=1)\n",
    "clip_weights2 = tf.assign(weights2, clipped_weights2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add an initializer and a saver:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can train the model. It's pretty much as usual, except that right after running the training_op, we run the clip_weights and clip_weights2 operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.9568\n",
      "1 Validation accuracy: 0.97\n",
      "2 Validation accuracy: 0.9712\n",
      "3 Validation accuracy: 0.9774\n",
      "4 Validation accuracy: 0.9784\n",
      "5 Validation accuracy: 0.977\n",
      "6 Validation accuracy: 0.9824\n",
      "7 Validation accuracy: 0.9816\n",
      "8 Validation accuracy: 0.9814\n",
      "9 Validation accuracy: 0.9818\n",
      "10 Validation accuracy: 0.9828\n",
      "11 Validation accuracy: 0.985\n",
      "12 Validation accuracy: 0.9832\n",
      "13 Validation accuracy: 0.9836\n",
      "14 Validation accuracy: 0.9846\n",
      "15 Validation accuracy: 0.9844\n",
      "16 Validation accuracy: 0.9844\n",
      "17 Validation accuracy: 0.984\n",
      "18 Validation accuracy: 0.985\n",
      "19 Validation accuracy: 0.9852\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:                                             \n",
    "    init.run()                                                          \n",
    "    for epoch in range(n_epochs):                                       \n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size): \n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            clip_weights.eval()\n",
    "            clip_weights2.eval()                                        \n",
    "        acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid})   \n",
    "        print(epoch, \"Validation accuracy:\", acc_valid)                 \n",
    "\n",
    "    save_path = saver.save(sess, \"./tf_logs/MaxNorm/my_model_final.ckpt\")              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation above is straightforward and it works fine, but it is a bit messy. A better approach is to define a max_norm_regularizer() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_norm_regularizer(threshold, axes=1, name=\"max_norm\",\n",
    "                         collection=\"max_norm\"):\n",
    "    def max_norm(weights):\n",
    "        clipped = tf.clip_by_norm(weights, clip_norm=threshold, axes=axes)\n",
    "        clip_weights = tf.assign(weights, clipped, name=name)\n",
    "        tf.add_to_collection(collection, clip_weights)\n",
    "        return None # there is no regularization loss term\n",
    "    return max_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you can call this function to get a max norm regularizer (with the threshold you want). When you create a hidden layer, you can pass this regularizer to the kernel_regularizer argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_norm_reg = max_norm_regularizer(threshold=1.0)\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,\n",
    "                              kernel_regularizer=max_norm_reg, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu,\n",
    "                              kernel_regularizer=max_norm_reg, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum)\n",
    "    training_op = optimizer.minimize(loss)    \n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training is as usual, except you must run the weights clipping operations after each training operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Validation accuracy: 0.9558\n",
      "1 Validation accuracy: 0.97\n",
      "2 Validation accuracy: 0.9726\n",
      "3 Validation accuracy: 0.975\n",
      "4 Validation accuracy: 0.976\n",
      "5 Validation accuracy: 0.9788\n",
      "6 Validation accuracy: 0.9808\n",
      "7 Validation accuracy: 0.9812\n",
      "8 Validation accuracy: 0.981\n",
      "9 Validation accuracy: 0.9812\n",
      "10 Validation accuracy: 0.9816\n",
      "11 Validation accuracy: 0.9826\n",
      "12 Validation accuracy: 0.9808\n",
      "13 Validation accuracy: 0.9822\n",
      "14 Validation accuracy: 0.9822\n",
      "15 Validation accuracy: 0.9822\n",
      "16 Validation accuracy: 0.9818\n",
      "17 Validation accuracy: 0.982\n",
      "18 Validation accuracy: 0.9812\n",
      "19 Validation accuracy: 0.982\n"
     ]
    }
   ],
   "source": [
    "clip_all_weights = tf.get_collection(\"max_norm\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            sess.run(clip_all_weights)\n",
    "        acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid}) \n",
    "        print(epoch, \"Validation accuracy:\", acc_valid)               \n",
    "\n",
    "    save_path = saver.save(sess, \"./tf_logs/MaxNorm/my_model_final.ckpt\")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
